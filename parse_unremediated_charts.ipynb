{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a619ac-8f43-47cc-9879-fa7d40ae0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8751742c-f516-45cb-8bd2-5a45b3959dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remediated_charts_dir = \"RemediatedCharts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56dbc84e-0bb8-4320-82d1-bac246983138",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirectory = \"access-control-srv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd191ac-f388-4106-a2a0-c31b82e63eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = remediated_charts_dir + \"/\" + subdirectory + \"/values.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f98ab98-a15b-4c00-8707-ef0acd3cab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data\n",
    "\n",
    "data = load_yaml(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f6681a-1cb6-45c2-bb45-3dc97e36b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"securityContext\", \"resources\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c1eacf1-97a2-49fa-956f-0da6ff9d6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nested_key(data, key):\n",
    "    for k, v in data.items():\n",
    "        if k == key:\n",
    "            yield v\n",
    "        if isinstance(v, dict):\n",
    "            yield from find_nested_key(v, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b675461-5926-43eb-850f-8cd6590b8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "security_context_vals = next(find_nested_key(data,'securityContext'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "726dc66b-cad7-46f0-a461-4f69ab9bd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_vals = next(find_nested_key(data,'resources'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30787476-ba6d-40c2-af12-b1638d8e171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('success.txt','r') as file:\n",
    "    successful_repos = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d808de12-45e6-4678-b7e5-7e6bfb8ae80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered_trivy_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a50a9ad-d126-4a55-aa96-b5226c1c7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target_split'] = df['Target'].apply(lambda x: '-'.join(x.split('-')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ccaaa97-2ff1-466d-9bd7-20d5cea2f738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "successful_repos_processed = ['-'.join(s.split('-')[:-1]) for s in successful_repos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3b2a463-bb9a-4cd7-b5bf-8236469949c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Target_split'].isin(successful_repos_processed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3895f0c7-329c-4fe3-b507-18a61e5c0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_resolutions = list(set(df['Resolution']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b8d17272-196b-4f9a-bda0-adcc271d40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d0ab286-71de-4a50-b017-34add7474527",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresolution_mappings.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "json.load('resolution_mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ee11d26-be55-4a9c-9762-4aa412673b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Manage namespace secrets are not allowed. Remove resource 'secrets' from role\",\n",
       " \"Remove the SYS_ADMIN capability from 'containers[].securityContext.capabilities.add'.\",\n",
       " \"Do not specify /var/run/docker.socket in 'spec.template.volumes.hostPath.path'.\",\n",
       " \"Set 'securityContext.runAsUser' to a non-zero integer or leave undefined.\",\n",
       " \"Set a limit value under 'containers[].resources.limits.cpu'.\",\n",
       " 'Remove sensitive content from configMap data value',\n",
       " 'Do not map the container ports to privileged host ports when starting a container.',\n",
       " \"Remove write permission verbs for resource 'configmaps'\",\n",
       " \"Remove verbs 'delete' and 'deletecollection' for resource 'pods/log' for Role and ClusterRole\",\n",
       " \"Remove write permission verbs for resource 'roles' and 'rolebindings'\",\n",
       " \"Set a limit value under 'containers[].resources.limits.memory'.\",\n",
       " \"Remove binding for clusterrole 'cluster-admin', 'admin' or 'edit'\",\n",
       " \"Set 'spec.securityContext.seccompProfile.type', 'spec.containers[*].securityContext.seccompProfile' and 'spec.initContainers[*].securityContext.seccompProfile' to 'RuntimeDefault' or undefined.\",\n",
       " 'Create a role which does not permit wildcard verb on wildcard resource',\n",
       " \"Set 'spec.containers[*].securityContext.capabilities.drop' to 'ALL' and only add 'NET_BIND_SERVICE' to 'spec.containers[*].securityContext.capabilities.add'.\",\n",
       " 'Remove password/secret from configMap data value',\n",
       " \"To mitigate potential security risks, it is strongly recommended to remove the NET_RAW capability from 'containers[].securityContext.capabilities.add'. It is advisable to follow the practice of dropping all capabilities and only adding the necessary ones.\",\n",
       " \"Do not set 'spec.template.spec.hostIPC' to true.\",\n",
       " 'Create a role which does not permit wildcard verb on specific resources',\n",
       " 'Do not set spec.containers[*].securityContext.capabilities.add and spec.initContainers[*].securityContext.capabilities.add.',\n",
       " 'Create a role which does not permit privilege escalation from node proxy',\n",
       " \"Remove write permission verbs for resource 'pods/exec'\",\n",
       " \"To mitigate potential security risks, it is strongly recommended to remove the SYS_MODULE capability from 'containers[].securityContext.capabilities.add'. It is advisable to follow the practice of dropping all capabilities and only adding the necessary ones.\",\n",
       " \"Remove '*' from 'rules.resources'. Provide specific list of resources to be managed by cluster role\",\n",
       " \"Use a specific container image tag that is not 'latest'.\",\n",
       " \"Networking resources are only allowed for verbs 'list', 'watch', 'get'\",\n",
       " 'Do not set spec.containers[*].ports[*].hostPort and spec.initContainers[*].ports[*].hostPort.',\n",
       " \"Do not set 'spec.template.spec.hostPID' to true.\",\n",
       " \"Change 'containers[].securityContext.readOnlyRootFilesystem' to 'true'.\",\n",
       " \"set the 'runtime/default' value from 'container.apparmor.security.beta.kubernetes.io'.\",\n",
       " \"Remove write permission verbs for resource 'configmaps' named 'aws-auth'\",\n",
       " \"Remove '*' from 'rules.resources'. Provide specific list of resources to be managed by role in namespace\",\n",
       " \"Set 'containers[].resources.requests.cpu'.\",\n",
       " 'Do not set spec.externalIPs',\n",
       " \"Set 'set containers[].securityContext.allowPrivilegeEscalation' to 'false'.\",\n",
       " \"Set 'containers[].securityContext.runAsNonRoot' to true.\",\n",
       " \"Do not set 'spec.volumes[*].hostPath'.\",\n",
       " \"Do not Set 'spec.volumes[*]' to any of the disallowed volume types.\",\n",
       " \"Kubernetes workloads resources are only allowed for verbs 'list', 'watch', 'get'\",\n",
       " \"Remove webhook configuration resouces/verbs, acceptable values for verbs ['get', 'list', 'watch']\",\n",
       " \"Set 'containers[].securityContext.runAsGroup' to a non-zero integer or leave undefined.\",\n",
       " \"Change 'containers[].securityContext.privileged' to 'false'.\",\n",
       " \"Set 'containers[].resources.requests.memory'.\",\n",
       " 'Specify seccomp either by annotation or by seccomp profile type having allowed values as per pod security standards',\n",
       " \"Set 'containers[].securityContext.runAsGroup' to an integer > 10000.\",\n",
       " \"Add 'ALL' to containers[].securityContext.capabilities.drop.\",\n",
       " \"Do not Set 'spec.volumes[*].hostPath.path' to any of the disallowed volumes.\",\n",
       " \"Manage secrets are not allowed. Remove resource 'secrets' from cluster role\",\n",
       " \"Do not set 'spec.template.spec.hostNetwork' to true.\",\n",
       " \"Set 'containers[].securityContext.runAsUser' to an integer > 10000.\"]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4496ad5-0333-4968-9f19-a87c5cc6273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_remediations(self, sections):\n",
    "    \"\"\"\n",
    "    Placeholder for remediation logic.\n",
    "    Modify the `SecurityContext`, `Resources`, and other sections\n",
    "    in the `values.yaml` file based on predefined remediation rules.\n",
    "    \"\"\"\n",
    "        # Example: Add remediation logic here\n",
    "        # For now, this section is left blank as per the requirements.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578eeea9-1340-4736-9ad4-98721c07887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelmChartParser:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.load_yaml()\n",
    "\n",
    "#Load the values.yaml file\n",
    "    def load_yaml(self):\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            self.data = yaml.safe_load(file)\n",
    "\n",
    "#Save the modified values.yaml file\n",
    "    def save_yaml(self):\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            yaml.dump(self.data, file, default_flow_style=False)\n",
    "\n",
    "#Recursively find nested key in YAML data\n",
    "    def find_nested_key(self, data, key):\n",
    "        if isinstance(data, dict):\n",
    "            for k, v in data.items():\n",
    "                if k == key:\n",
    "                    yield v\n",
    "                if isinstance(v, dict) or isinstance(v, list):\n",
    "                    yield from self.find_nested_key(v, key)\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                yield from self.find_nested_key(item, key)\n",
    "\n",
    "#Identify the sections we're interested in (e.g., SecurityContext, Resources)\n",
    "    def identify_sections(self):\n",
    "        sections = {\n",
    "            \"SecurityContext\": list(self.find_nested_key(self.data, \"securityContext\")),\n",
    "            \"Resources\": list(self.find_nested_key(self.data, \"resources\")),\n",
    "            # Add more sections as needed\n",
    "        }\n",
    "        return sections\n",
    "\n",
    "    def apply_remediations(self, sections):\n",
    "        \"\"\"\n",
    "        Placeholder for remediation logic.\n",
    "        Modify the `SecurityContext`, `Resources`, and other sections\n",
    "        in the `values.yaml` file based on predefined remediation rules.\n",
    "        \"\"\"\n",
    "        # Example: Add remediation logic here\n",
    "        # For now, this section is left blank as per the requirements.\n",
    "        pass\n",
    "\n",
    "#Run the parser to identify sections and apply remediations.\n",
    "    def run_parser(self):\n",
    "        print(\"Identifying sections in values.yaml...\")\n",
    "        sections = self.identify_sections()\n",
    "        print(\"Sections found:\", sections)\n",
    "        \n",
    "        print(\"Applying remediations (to be implemented)...\")\n",
    "        self.apply_remediations(sections)\n",
    "\n",
    "        # Save the modified YAML file\n",
    "        self.save_yaml()\n",
    "        print(\"Modifications saved to values.yaml\")\n",
    "\n",
    "file_path = RemediatedCharts + \"/\" + Chart + \"/\" + values.yaml \n",
    "parser = HelmChartParser(file_path)\n",
    "parser.run_parser()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
