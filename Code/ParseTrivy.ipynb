{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97fa37db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All JSON files have been appended to the CSV file 'E:\\SVA_Research\\AdamStuff\\all_scans.csv'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Specify the folder containing JSON files\n",
    "json_folder = r\"directory(use one backslash)\"\n",
    "\n",
    "#Specify Output folder\n",
    "output_folder = r\"directory(use one backslash because of r)\"\n",
    "\n",
    "# Specify the path to the output CSV file\n",
    "csv_file = os.path.join(output_folder, \"all_scans.csv\")\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "csv_file_exists = os.path.exists(csv_file)\n",
    "\n",
    "# List of field names for CSV columns\n",
    "csv_columns = [\"Target\", \"Type\", \"ID\", \"AVDID\", \"Title\", \"Description\", \"Message\", \"Namespace\", \"Query\", \"Resolution\", \"Severity\", \"PrimaryURL\", \"References\", \"Provider\", \"Service\", \"StartLine\", \"EndLine\"]\n",
    "\n",
    "# Open the CSV file in append mode or create a new file if it doesn't exist\n",
    "with open(csv_file, 'a', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "\n",
    "    # Write header only if the file is newly created\n",
    "    if not csv_file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    # Process each JSON file\n",
    "    for json_file_name in os.listdir(json_folder):\n",
    "        if json_file_name.endswith('.json'):\n",
    "            # Construct the full path to the JSON file\n",
    "            json_file_path = os.path.join(json_folder, json_file_name)\n",
    "\n",
    "            # Read the JSON file\n",
    "            with open(json_file_path, 'r') as json_file:\n",
    "                data = json.load(json_file)\n",
    "\n",
    "            # Extract relevant information and normalize the data\n",
    "            records = []\n",
    "            for result in data['Results']:\n",
    "                for misconfiguration in result['Misconfigurations']:\n",
    "                    causemetadata = misconfiguration.get('CauseMetadata', {})\n",
    "                    record = {\n",
    "                        \"Target\": result.get('Target', ''),\n",
    "                        \"Type\": misconfiguration.get('Type', ''),\n",
    "                        \"ID\": misconfiguration.get('ID', ''),\n",
    "                        \"AVDID\": misconfiguration.get('AVDID', ''),\n",
    "                        \"Title\": misconfiguration.get('Title', ''),\n",
    "                        \"Description\": misconfiguration.get('Description', ''),\n",
    "                        \"Message\": misconfiguration.get('Message', ''),\n",
    "                        \"Namespace\": misconfiguration.get('Namespace', ''),\n",
    "                        \"Query\": misconfiguration.get('Query', ''),\n",
    "                        \"Resolution\": misconfiguration.get('Resolution', ''),\n",
    "                        \"Severity\": misconfiguration.get('Severity', ''),\n",
    "                        \"PrimaryURL\": misconfiguration.get('PrimaryURL', ''),\n",
    "                        \"References\": ', '.join(misconfiguration.get('References', [])),\n",
    "                        \"Provider\": causemetadata.get('Provider', ''),\n",
    "                        \"Service\": causemetadata.get('Service', ''),\n",
    "                        \"StartLine\": causemetadata.get('StartLine', ''),\n",
    "                        \"EndLine\": causemetadata.get('EndLine', '')\n",
    "                    }\n",
    "                    records.append(record)\n",
    "\n",
    "            # Append the normalized data to the CSV file\n",
    "            for record in records:\n",
    "                writer.writerow(record)\n",
    "\n",
    "print(f\"All JSON files have been appended to the CSV file '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e42bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All JSON files have been appended to the CSV file 'C:\\Users\\adamr\\Desktop\\out\\all_scans.csv'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Specify the folder containing JSON files\n",
    "json_folder = r\"C:\\Users\\adamr\\Desktop\\in\"\n",
    "\n",
    "# Specify Output folder\n",
    "output_folder = r\"C:\\Users\\adamr\\Desktop\\out\"\n",
    "\n",
    "# Specify the path to the output CSV file\n",
    "csv_file = os.path.join(output_folder, \"all_scans.csv\")\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "csv_file_exists = os.path.exists(csv_file)\n",
    "\n",
    "# List of field names for CSV columns\n",
    "csv_columns = [\"Target\", \"Type\", \"ID\", \"AVDID\", \"Title\", \"Description\", \"Message\", \"Namespace\", \"Query\", \"Resolution\", \"Severity\", \"PrimaryURL\", \"References\", \"Provider\", \"Service\", \"StartLine\", \"EndLine\"]\n",
    "\n",
    "# Open the CSV file in append mode or create a new file if it doesn't exist\n",
    "with open(csv_file, 'a', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "\n",
    "    # Write header only if the file is newly created\n",
    "    if not csv_file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    # Process each JSON file\n",
    "    for json_file_name in os.listdir(json_folder):\n",
    "        if json_file_name.endswith('.json'):\n",
    "            # Construct the full path to the JSON file\n",
    "            json_file_path = os.path.join(json_folder, json_file_name)\n",
    "\n",
    "            # Read the JSON file\n",
    "            with open(json_file_path, 'r') as json_file:\n",
    "                data = json.load(json_file)\n",
    "\n",
    "            # Check if the JSON data has results\n",
    "            if 'Results' not in data:\n",
    "                print(f\"Skipping '{json_file_name}' as it doesn't have results.\")\n",
    "                continue\n",
    "\n",
    "            # Extract relevant information and normalize the data\n",
    "            records = []\n",
    "            for result in data['Results']:\n",
    "                for misconfiguration in result['Misconfigurations']:\n",
    "                    causemetadata = misconfiguration.get('CauseMetadata', {})\n",
    "                    record = {\n",
    "                        \"Target\": result.get('Target', ''),\n",
    "                        \"Type\": misconfiguration.get('Type', ''),\n",
    "                        \"ID\": misconfiguration.get('ID', ''),\n",
    "                        \"AVDID\": misconfiguration.get('AVDID', ''),\n",
    "                        \"Title\": misconfiguration.get('Title', ''),\n",
    "                        \"Description\": misconfiguration.get('Description', ''),\n",
    "                        \"Message\": misconfiguration.get('Message', ''),\n",
    "                        \"Namespace\": misconfiguration.get('Namespace', ''),\n",
    "                        \"Query\": misconfiguration.get('Query', ''),\n",
    "                        \"Resolution\": misconfiguration.get('Resolution', ''),\n",
    "                        \"Severity\": misconfiguration.get('Severity', ''),\n",
    "                        \"PrimaryURL\": misconfiguration.get('PrimaryURL', ''),\n",
    "                        \"References\": ', '.join(misconfiguration.get('References', [])),\n",
    "                        \"Provider\": causemetadata.get('Provider', ''),\n",
    "                        \"Service\": causemetadata.get('Service', ''),\n",
    "                        \"StartLine\": causemetadata.get('StartLine', ''),\n",
    "                        \"EndLine\": causemetadata.get('EndLine', '')\n",
    "                    }\n",
    "                    records.append(record)\n",
    "\n",
    "            # Append the normalized data to the CSV file\n",
    "            for record in records:\n",
    "                writer.writerow(record)\n",
    "\n",
    "print(f\"All JSON files have been appended to the CSV file '{csv_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Specify the folder containing JSON files\n",
    "json_folder = r\"directory(use one backslash)\"\n",
    "\n",
    "# Specify Output folder\n",
    "output_folder = r\"directory(use one backslash because of r)\"\n",
    "\n",
    "# Specify the path to the output CSV file\n",
    "csv_file = os.path.join(output_folder, \"all_scans.csv\")\n",
    "\n",
    "# Specify the path to the output CSV file for skipped files\n",
    "skipped_csv_file = os.path.join(output_folder, \"skipped_files.csv\")\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "csv_file_exists = os.path.exists(csv_file)\n",
    "skipped_csv_file_exists = os.path.exists(skipped_csv_file)\n",
    "\n",
    "# List of field names for CSV columns\n",
    "csv_columns = [\"Target\", \"Type\", \"ID\", \"AVDID\", \"Title\", \"Description\", \"Message\", \"Namespace\", \"Query\", \"Resolution\", \"Severity\", \"PrimaryURL\", \"References\", \"Provider\", \"Service\", \"StartLine\", \"EndLine\"]\n",
    "\n",
    "# List to store skipped files\n",
    "skipped_files = []\n",
    "\n",
    "# Open the CSV file in append mode or create a new file if it doesn't exist\n",
    "with open(csv_file, 'a', newline='') as csvfile, open(skipped_csv_file, 'a', newline='') as skipped_csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "    skipped_writer = csv.writer(skipped_csvfile)\n",
    "\n",
    "    # Write header only if the file is newly created\n",
    "    if not csv_file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    # Write header only if the skipped files CSV file is newly created\n",
    "    if not skipped_csv_file_exists:\n",
    "        skipped_writer.writerow([\"Skipped File\"])\n",
    "\n",
    "    # Process each JSON file\n",
    "    for json_file_name in os.listdir(json_folder):\n",
    "        if json_file_name.endswith('.json'):\n",
    "            # Construct the full path to the JSON file\n",
    "            json_file_path = os.path.join(json_folder, json_file_name)\n",
    "\n",
    "            try:\n",
    "                # Read the JSON file\n",
    "                with open(json_file_path, 'r') as json_file:\n",
    "                    data = json.load(json_file)\n",
    "\n",
    "                # Check if the JSON data has results\n",
    "                if 'Results' not in data:\n",
    "                    print(f\"Skipping '{json_file_name}' as it doesn't have results.\")\n",
    "                    skipped_files.append(json_file_name)\n",
    "                    continue\n",
    "\n",
    "                # Extract relevant information and normalize the data\n",
    "                records = []\n",
    "                for result in data['Results']:\n",
    "                    for misconfiguration in result['Misconfigurations']:\n",
    "                        causemetadata = misconfiguration.get('CauseMetadata', {})\n",
    "                        record = {\n",
    "                            \"Target\": result.get('Target', ''),\n",
    "                            \"Type\": misconfiguration.get('Type', ''),\n",
    "                            \"ID\": misconfiguration.get('ID', ''),\n",
    "                            \"AVDID\": misconfiguration.get('AVDID', ''),\n",
    "                            \"Title\": misconfiguration.get('Title', ''),\n",
    "                            \"Description\": misconfiguration.get('Description', ''),\n",
    "                            \"Message\": misconfiguration.get('Message', ''),\n",
    "                            \"Namespace\": misconfiguration.get('Namespace', ''),\n",
    "                            \"Query\": misconfiguration.get('Query', ''),\n",
    "                            \"Resolution\": misconfiguration.get('Resolution', ''),\n",
    "                            \"Severity\": misconfiguration.get('Severity', ''),\n",
    "                            \"PrimaryURL\": misconfiguration.get('PrimaryURL', ''),\n",
    "                            \"References\": ', '.join(misconfiguration.get('References', [])),\n",
    "                            \"Provider\": causemetadata.get('Provider', ''),\n",
    "                            \"Service\": causemetadata.get('Service', ''),\n",
    "                            \"StartLine\": causemetadata.get('StartLine', ''),\n",
    "                            \"EndLine\": causemetadata.get('EndLine', '')\n",
    "                        }\n",
    "                        records.append(record)\n",
    "\n",
    "                # Append the normalized data to the CSV file\n",
    "                for record in records:\n",
    "                    writer.writerow(record)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing '{json_file_name}': {str(e)}\")\n",
    "                skipped_files.append(json_file_name)\n",
    "                skipped_writer.writerow([json_file_name])\n",
    "\n",
    "print(f\"All JSON files have been appended to the CSV file '{csv_file}'.\")\n",
    "print(f\"Skipped files have been logged in '{skipped_csv_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
